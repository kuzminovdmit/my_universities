{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, has_intercept=True) -> None:\n",
    "        self.has_intercept = has_intercept\n",
    "    \n",
    "    def fit_intercept(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.hstack((X, np.ones((X.shape[0], 1)))) if self.has_intercept else X\n",
    "    \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "        X = self.fit_intercept(X)\n",
    "\n",
    "        self.weights = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "\n",
    "        return self.weights\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray | None:\n",
    "        X = self.fit_intercept(X)\n",
    "\n",
    "        self.y_pred = None\n",
    "\n",
    "        try:\n",
    "            self.y_pred = X @ self.weights\n",
    "        except AttributeError:\n",
    "            print(\"Please, fit train X set first (weights aren't calculated yet)\")\n",
    "        \n",
    "        return self.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 5 * x + 6\n",
    "\n",
    "X = np.linspace(-5, 5, 50)\n",
    "y = f(X) + np.random.randn(50) * 5\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(X, f(X), label=\"3x + 5\", c=\"g\")\n",
    "plt.scatter(X_train, y_train, label=\"train\")\n",
    "plt.scatter(X_test, y_test, label=\"test\")\n",
    "\n",
    "plt.title(\"Dataset\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "\n",
    "weights = regressor.fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "print(f\"y = {weights[0]:.2f}x + {weights[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.scatter(X_train, y_train, label=\"train\", c=\"g\")\n",
    "plt.plot(X_train, f(X_train), label=\"3x + 5\")\n",
    "plt.plot(X_train, regressor.predict(X_train[:, np.newaxis]), label=\"predicted\")\n",
    "\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.title(\"train\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.scatter(X_test, y_test, label=\"test\", c=\"g\")\n",
    "plt.plot(X_test, f(X_test), label=\"3x + 5\")\n",
    "plt.plot(X_test, regressor.predict(X_test[:, np.newaxis]), label=\"predicted\")\n",
    "\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.title(\"test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train MSE: {mean_squared_error(y_train, regressor.predict(X_train[:, np.newaxis]))}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, regressor.predict(X_test[:, np.newaxis]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientLinearRegression(LinearRegression):\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray, lr=0.01, max_iter=100, n_sample=0) -> np.ndarray:\n",
    "        self.weights = np.random.randn(\n",
    "            X.shape[1] + 1 if self.has_intercept else X.shape[1]\n",
    "        )\n",
    "        \n",
    "        X_train = np.hstack((X, np.ones((X.shape[0], 1)))) if self.has_intercept else X\n",
    "\n",
    "        self.losses = []\n",
    "\n",
    "        while max_iter:\n",
    "            y_pred = self.predict(X)\n",
    "            self.losses.append(mean_squared_error(y_pred, Y))\n",
    "            grad = self._gradient(X_train, Y, y_pred, n_sample)\n",
    "            self.weights -= lr * grad\n",
    "            max_iter -= 1\n",
    "        \n",
    "        return self.weights\n",
    "\n",
    "    def _gradient(self, X: np.ndarray, Y: np.ndarray, y_pred: np.ndarray, n_sample=0) -> np.ndarray:\n",
    "        if n_sample:\n",
    "            inds = np.random.choice(np.arange(X.shape[0]), size=n_sample, replace=False)\n",
    "            grad = (2 * (y_pred[inds] - Y[inds])[:, np.newaxis] * X[inds]).mean(axis=0)\n",
    "        else:\n",
    "            grad = (2 * (y_pred - Y)[:, np.newaxis] * X).mean(axis=0)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = GradientLinearRegression(has_intercept=True)\n",
    "\n",
    "weights = regressor.fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "print(f\"y = {weights[0]:.2f}x + {weights[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.scatter(X_train, y_train, label=\"train\", c=\"g\")\n",
    "plt.plot(X_train, f(X_train), label=\"5x + 6\")\n",
    "plt.plot(X_train, regressor.predict(X_train[:, np.newaxis]), label=\"predicted\")\n",
    "\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.title(\"train\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.scatter(X_test, y_test, label=\"test\", c=\"g\")\n",
    "plt.plot(X_test, f(X_test), label=\"5x + 6\")\n",
    "plt.plot(X_test, regressor.predict(X_test[:, np.newaxis]), label=\"predicted\")\n",
    "\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.title(\"test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for n_sample in [0, 1, 2, 4]:\n",
    "    regressor = GradientLinearRegression(has_intercept=True)\n",
    "\n",
    "    weights = regressor.fit(X_train[:, np.newaxis], y_train, n_sample=n_sample)\n",
    "\n",
    "    plt.plot(regressor.losses, label=f\"{n_sample} mini-batch size\")\n",
    "\n",
    "plt.title(\"Gradient Descent Learning\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-universities-WH-lEkkT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
